{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPV0Ub8JsmI6vQLvmrlgiLz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dev0419/BDA_Lab/blob/main/Lab-3/Entity_Resolution_L3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Develop a PySpark script to clean and preprocess data before performing entity resolution. Include steps like tokenization and normalization."
      ],
      "metadata": {
        "id": "Tun02g6V8EaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when\n",
        "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
        "\n",
        "spark = SparkSession.builder.appName('res').getOrCreate()\n",
        "\n",
        "data = spark.read.csv('/content/data', inferSchema=True, header=True, nullValue='?')\n",
        "\n",
        "data = data.fillna({'id_1': '', 'id_2': ''})\n",
        "\n",
        "tokenizer_id_1 = Tokenizer(inputCol='id_1', outputCol='id_1_tokens')\n",
        "data = tokenizer_id_1.transform(data)\n",
        "\n",
        "tokenizer_id_2 = Tokenizer(inputCol='id_2', outputCol='id_2_tokens')\n",
        "data = tokenizer_id_2.transform(data)\n",
        "\n",
        "word2vec_id_1 = Word2Vec(vectorSize=5, minCount=0, inputCol='id_1_tokens', outputCol='id_1_vec')\n",
        "model_id_1 = word2vec_id_1.fit(data)\n",
        "data = model_id_1.transform(data)\n",
        "\n",
        "word2vec_id_2 = Word2Vec(vectorSize=5, minCount=0, inputCol='id_2_tokens', outputCol='id_2_vec')\n",
        "model_id_2 = word2vec_id_2.fit(data)\n",
        "data = model_id_2.transform(data)\n",
        "\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cT2BhE_8Apw",
        "outputId": "c63d6c52-4226-4dcb-b8d1-933f450a3f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+-----------+-----------+--------------------+--------------------+\n",
            "| id_1| id_2|cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|id_1_tokens|id_2_tokens|            id_1_vec|            id_2_vec|\n",
            "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+-----------+-----------+--------------------+--------------------+\n",
            "| 3148| 8326|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|     [3148]|     [8326]|[0.02116392925381...|[-0.0531290657818...|\n",
            "|14055|94934|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [14055]|    [94934]|[-0.0012151598930...|[-0.0749845355749...|\n",
            "|33948|34740|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [33948]|    [34740]|[0.09415061771869...|[-0.0646289363503...|\n",
            "|  946|71870|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|      [946]|    [71870]|[0.05668329074978...|[-0.0780718103051...|\n",
            "|64880|71676|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [64880]|    [71676]|[-0.0114681962877...|[0.08934281766414...|\n",
            "|25739|45991|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [25739]|    [45991]|[0.03523911163210...|[0.00856009684503...|\n",
            "|62415|93584|           1|           0|           1|           0|      1|     1|     1|     1|      0|    true|    [62415]|    [93584]|[0.04841632768511...|[-0.0538546070456...|\n",
            "|27995|31399|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [27995]|    [31399]|[-8.8319776114076...|[-0.0470940098166...|\n",
            "| 4909|12238|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|     [4909]|    [12238]|[-0.0134054180234...|[-0.0925781950354...|\n",
            "|15161|16743|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [15161]|    [16743]|[0.05226856470108...|[-0.0540292970836...|\n",
            "|31703|37310|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [31703]|    [37310]|[0.08093899488449...|[-0.0662520900368...|\n",
            "|30213|36558|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [30213]|    [36558]|[-0.0350036621093...|[0.07173719257116...|\n",
            "|56596|56630|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [56596]|    [56630]|[0.06952358782291...|[-0.0506885647773...|\n",
            "|16481|21174|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [16481]|    [21174]|[-0.0930627360939...|[0.05931646749377...|\n",
            "|32649|37094|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [32649]|    [37094]|[0.01226713694632...|[1.87563899089582...|\n",
            "|34268|37260|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [34268]|    [37260]|[0.05555062368512...|[0.03882305696606...|\n",
            "|66117|69253|           1|           0|           1|           0|      1|     1|     1|     1|      0|    true|    [66117]|    [69253]|[0.08165027201175...|[2.46345996856689...|\n",
            "| 2771|31982|           1|           0|           1|           0|      0|     1|     1|     1|      1|    true|     [2771]|    [31982]|[0.03036198578774...|[-0.0216610077768...|\n",
            "|23557|29673|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [23557]|    [29673]|[0.04089075326919...|[-0.0800410658121...|\n",
            "|37156|39557|           1|           0|           1|           0|      1|     1|     1|     1|      1|    true|    [37156]|    [39557]|[0.08194354921579...|[0.04244996234774...|\n",
            "+-----+-----+------------+------------+------------+------------+-------+------+------+------+-------+--------+-----------+-----------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Implement a PySpark program that computes similarity scores between records using a chosen similarity metric."
      ],
      "metadata": {
        "id": "b_HxvTF2EudL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "misses = data[data['is_match'] == 'false']\n",
        "matches = data[data['is_match'] == 'true']\n",
        "good_features = [\"cmp_lname_c1\",\"cmp_plz\",\"cmp_by\",\"cmp_bd\",\"cmp_bm\"]\n",
        "sum_expression = \" + \".join(good_features)\n",
        "scored = data.fillna(0,subset = good_features).withColumn('score',expr(sum_expression)).select('score','is_match')\n",
        "scored.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLQEsA9fEy9y",
        "outputId": "4f78016a-ebd1-4f63-c985-a8bfabaceffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+\n",
            "|score|is_match|\n",
            "+-----+--------+\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  4.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  4.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "|  5.0|    true|\n",
            "+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Implement a PySpark program to evaluate the precision, recall, and F1-score of an entity resolution model"
      ],
      "metadata": {
        "id": "oy5j4xB7Rvk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "def calculate_metrics(scored, threshold):\n",
        "    tp = scored.filter((col('score') >= threshold) & (col('is_match') == 'true')).count()\n",
        "    fp = scored.filter((col('score') >= threshold) & (col('is_match') == 'false')).count()\n",
        "    fn = scored.filter((col('score') < threshold) & (col('is_match') == 'true')).count()\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "threshold = 4.0\n",
        "\n",
        "precision, recall, f1_score = calculate_metrics(scored, threshold)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHMuKjCrRxqJ",
        "outputId": "9e14d770-7e41-4d1e-c2d5-d42d20b2e8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9703831132601822\n",
            "Recall: 0.9974193548387097\n",
            "F1 Score: 0.9837155044422973\n"
          ]
        }
      ]
    }
  ]
}